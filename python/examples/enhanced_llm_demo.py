#!/usr/bin/env python3
"""
Enhanced LLM Commands Demo
==========================

This script demonstrates the new enhanced LLM commands available in
Agent as Code Python package v1.1.0+.

Features demonstrated:
- Intelligent agent creation
- Model optimization
- Benchmarking
- Agent deployment
- Model analysis
"""

from agent_as_code import AgentCLI
import time

def main():
    """Demonstrate enhanced LLM commands."""
    print("ğŸ§  Enhanced LLM Commands Demo")
    print("=" * 50)
    
    try:
        # Initialize the CLI
        print("ğŸ”§ Initializing Agent CLI...")
        cli = AgentCLI()
        print("âœ… CLI initialized successfully")
        
        # List available models
        print("\nğŸ“‹ Listing available models...")
        if cli.list_models():
            print("âœ… Models listed successfully")
        else:
            print("âš ï¸  No models available or Ollama not running")
        
        # Create an intelligent agent
        print("\nğŸš€ Creating intelligent chatbot agent...")
        if cli.create_agent('chatbot'):
            print("âœ… Chatbot agent created successfully")
            print("ğŸ“ Project directory: chatbot-agent")
        else:
            print("âŒ Failed to create chatbot agent")
            return
        
        # Create another agent for demonstration
        print("\nğŸš€ Creating intelligent sentiment analyzer agent...")
        if cli.create_agent('sentiment-analyzer'):
            print("âœ… Sentiment analyzer agent created successfully")
            print("ğŸ“ Project directory: sentiment-analyzer-agent")
        else:
            print("âŒ Failed to create sentiment analyzer agent")
            return
        
        # Deploy and test the first agent
        print("\nğŸš€ Deploying and testing chatbot agent...")
        if cli.deploy_agent('chatbot-agent', test_suite='comprehensive'):
            print("âœ… Chatbot agent deployed and tested successfully")
            print("ğŸ”— Access: http://localhost:8080")
        else:
            print("âŒ Failed to deploy chatbot agent")
        
        # Demonstrate model optimization (if models are available)
        print("\nâš¡ Demonstrating model optimization...")
        print("Note: This requires models to be available via Ollama")
        if cli.optimize_model('llama2', 'chatbot'):
            print("âœ… Model optimization completed")
        else:
            print("âš ï¸  Model optimization failed (model may not be available)")
        
        # Demonstrate benchmarking
        print("\nğŸ“Š Running model benchmarks...")
        if cli.benchmark_models(['chatbot', 'sentiment-analysis']):
            print("âœ… Benchmarking completed")
        else:
            print("âš ï¸  Benchmarking failed (models may not be available)")
        
        # Demonstrate model analysis
        print("\nğŸ” Analyzing model capabilities...")
        if cli.analyze_model('llama2', detailed=True):
            print("âœ… Model analysis completed")
        else:
            print("âš ï¸  Model analysis failed (model may not be available)")
        
        print("\nğŸ‰ Enhanced LLM Commands Demo Completed!")
        print("\nğŸ’¡ Next steps:")
        print("   - Explore the generated agent projects")
        print("   - Customize the agents for your specific needs")
        print("   - Deploy to production environments")
        print("   - Integrate with your existing workflows")
        
    except Exception as e:
        print(f"âŒ Error during demo: {e}")
        print("\nğŸ’¡ Troubleshooting tips:")
        print("   - Ensure Ollama is running: ollama serve")
        print("   - Pull required models: ollama pull llama2")
        print("   - Check network connectivity")
        print("   - Verify Go binary is available")

if __name__ == "__main__":
    main()
