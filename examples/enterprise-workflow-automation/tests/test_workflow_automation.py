#!/usr/bin/env python3
"""
Tests for Enterprise Workflow Automation Agent
Generated by Agent-as-Code LLM Intelligence

Comprehensive test suite covering all functionality including:
- Workflow management
- Compliance monitoring
- Resource management
- Security features
- API endpoints
"""

import pytest
import asyncio
import json
from datetime import datetime
from unittest.mock import Mock, patch, AsyncMock
from fastapi.testclient import TestClient
from fastapi import HTTPException

# Import the application
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from main import app, WorkflowEngine, WorkflowRequest, WorkflowPriority, WorkflowStatus

# Test client
client = TestClient(app)

# Mock authentication
@pytest.fixture
def mock_auth():
    """Mock authentication for testing"""
    with patch('main.get_current_user') as mock:
        mock.return_value = {"user_id": "test-user", "team": "platform-engineering"}
        yield mock

@pytest.fixture
def workflow_engine():
    """Create a fresh workflow engine for testing"""
    return WorkflowEngine()

@pytest.fixture
def sample_workflow_request():
    """Sample workflow request for testing"""
    return WorkflowRequest(
        name="test-workflow",
        description="Test workflow for unit testing",
        priority=WorkflowPriority.MEDIUM,
        parameters={"test": True},
        timeout=3600,
        tags=["test", "unit-test"]
    )

class TestWorkflowEngine:
    """Test workflow engine functionality"""
    
    def test_create_workflow(self, workflow_engine, sample_workflow_request):
        """Test workflow creation"""
        # Test workflow creation
        workflow_id = asyncio.run(workflow_engine.create_workflow(sample_workflow_request))
        
        assert workflow_id is not None
        assert workflow_id.startswith("wf_")
        
        # Verify workflow was created
        workflow = workflow_engine.get_workflow(workflow_id)
        assert workflow is not None
        assert workflow["name"] == "test-workflow"
        assert workflow["status"] == WorkflowStatus.PENDING
        assert workflow["priority"] == WorkflowPriority.MEDIUM
    
    def test_execute_workflow(self, workflow_engine, sample_workflow_request):
        """Test workflow execution"""
        # Create workflow
        workflow_id = asyncio.run(workflow_engine.create_workflow(sample_workflow_request))
        
        # Execute workflow
        result = asyncio.run(workflow_engine.execute_workflow(workflow_id))
        
        # Verify execution
        assert result["status"] == WorkflowStatus.COMPLETED
        assert result["progress"] == 100.0
        assert result["execution_time"] is not None
        assert result["compliance_score"] > 0
    
    def test_workflow_not_found(self, workflow_engine):
        """Test handling of non-existent workflow"""
        with pytest.raises(ValueError, match="Workflow wf_nonexistent not found"):
            asyncio.run(workflow_engine.execute_workflow("wf_nonexistent"))
    
    def test_list_workflows(self, workflow_engine, sample_workflow_request):
        """Test workflow listing"""
        # Create multiple workflows
        workflow_ids = []
        for i in range(3):
            request = WorkflowRequest(
                name=f"test-workflow-{i}",
                description=f"Test workflow {i}",
                priority=WorkflowPriority.MEDIUM
            )
            workflow_id = asyncio.run(workflow_engine.create_workflow(request))
            workflow_ids.append(workflow_id)
        
        # List all workflows
        workflows = workflow_engine.list_workflows()
        assert len(workflows) == 3
        
        # List by status
        pending_workflows = workflow_engine.list_workflows(WorkflowStatus.PENDING)
        assert len(pending_workflows) == 3
        
        # Execute one workflow
        asyncio.run(workflow_engine.execute_workflow(workflow_ids[0]))
        
        # Check counts
        active_workflows = workflow_engine.list_workflows()
        completed_workflows = workflow_engine.list_workflows(WorkflowStatus.COMPLETED)
        
        assert len(active_workflows) == 2
        assert len(completed_workflows) == 1

class TestAPIEndpoints:
    """Test API endpoint functionality"""
    
    def test_health_check(self, mock_auth):
        """Test health check endpoint"""
        response = client.get("/health")
        assert response.status_code == 200
        
        data = response.json()
        assert data["status"] == "healthy"
        assert "timestamp" in data
        assert data["environment"] == "production"
        assert data["team"] == "platform-engineering"
    
    def test_metrics_endpoint(self, mock_auth):
        """Test Prometheus metrics endpoint"""
        response = client.get("/metrics")
        assert response.status_code == 200
        assert "text/plain" in response.headers["content-type"]
        
        # Check for expected metrics
        metrics_content = response.text
        assert "http_requests_total" in metrics_content
        assert "active_workflows" in metrics_content
    
    def test_create_workflow(self, mock_auth):
        """Test workflow creation endpoint"""
        workflow_data = {
            "name": "api-test-workflow",
            "description": "Workflow created via API",
            "priority": "high",
            "parameters": {"source": "api-test"},
            "timeout": 1800,
            "tags": ["api", "test"]
        }
        
        response = client.post("/workflows", json=workflow_data)
        assert response.status_code == 200
        
        data = response.json()
        assert data["name"] == "api-test-workflow"
        assert data["status"] == "pending"
        assert data["priority"] == "high"
        assert "id" in data
    
    def test_get_workflow(self, mock_auth):
        """Test workflow retrieval endpoint"""
        # First create a workflow
        workflow_data = {
            "name": "get-test-workflow",
            "description": "Workflow for retrieval test",
            "priority": "medium"
        }
        
        create_response = client.post("/workflows", json=workflow_data)
        workflow_id = create_response.json()["id"]
        
        # Then retrieve it
        response = client.get(f"/workflows/{workflow_id}")
        assert response.status_code == 200
        
        data = response.json()
        assert data["id"] == workflow_id
        assert data["name"] == "get-test-workflow"
    
    def test_get_nonexistent_workflow(self, mock_auth):
        """Test retrieval of non-existent workflow"""
        response = client.get("/workflows/wf_nonexistent")
        assert response.status_code == 404
        assert "Workflow not found" in response.json()["detail"]
    
    def test_list_workflows(self, mock_auth):
        """Test workflow listing endpoint"""
        response = client.get("/workflows")
        assert response.status_code == 200
        
        workflows = response.json()
        assert isinstance(workflows, list)
    
    def test_list_workflows_by_status(self, mock_auth):
        """Test workflow listing with status filter"""
        response = client.get("/workflows?status=pending")
        assert response.status_code == 200
        
        workflows = response.json()
        assert isinstance(workflows, list)
    
    def test_cancel_workflow(self, mock_auth):
        """Test workflow cancellation"""
        # Create a workflow
        workflow_data = {
            "name": "cancel-test-workflow",
            "description": "Workflow for cancellation test",
            "priority": "low"
        }
        
        create_response = client.post("/workflows", json=workflow_data)
        workflow_id = create_response.json()["id"]
        
        # Cancel it
        response = client.delete(f"/workflows/{workflow_id}")
        assert response.status_code == 200
        assert "cancelled successfully" in response.json()["message"]
    
    def test_compliance_score(self, mock_auth):
        """Test compliance score endpoint"""
        response = client.get("/compliance/score")
        assert response.status_code == 200
        
        data = response.json()
        assert "score" in data
        assert "status" in data
        assert "total_workflows" in data
        assert data["score"] >= 0 and data["score"] <= 100
    
    def test_resource_metrics(self, mock_auth):
        """Test resource metrics endpoint"""
        response = client.get("/resources/metrics")
        assert response.status_code == 200
        
        data = response.json()
        assert "cpu_utilization" in data
        assert "memory_utilization" in data
        assert "disk_utilization" in data
        assert "network_io" in data
        assert "timestamp" in data
    
    def test_deployment_webhook(self, mock_auth):
        """Test deployment webhook endpoint"""
        webhook_data = {
            "repository": "test-repo",
            "branch": "main",
            "commit": "abc123",
            "environment": "production"
        }
        
        response = client.post("/webhooks/deploy", json=webhook_data)
        assert response.status_code == 200
        
        data = response.json()
        assert "Deployment workflow created" in data["message"]
        assert "workflow_id" in data

class TestSecurity:
    """Test security features"""
    
    def test_authentication_required(self):
        """Test that authentication is required for protected endpoints"""
        # Test without authentication
        response = client.post("/workflows", json={
            "name": "unauthorized-workflow",
            "description": "This should fail"
        })
        assert response.status_code == 401
        assert "Authentication required" in response.json()["detail"]
    
    def test_cors_headers(self):
        """Test CORS headers are present"""
        response = client.options("/health")
        assert response.status_code == 200
        
        # Check CORS headers
        assert "access-control-allow-origin" in response.headers
        assert "access-control-allow-methods" in response.headers

class TestErrorHandling:
    """Test error handling and validation"""
    
    def test_invalid_workflow_request(self, mock_auth):
        """Test validation of workflow requests"""
        # Test empty name
        response = client.post("/workflows", json={
            "name": "",
            "description": "Invalid workflow"
        })
        assert response.status_code == 422
        
        # Test missing required fields
        response = client.post("/workflows", json={
            "description": "Missing name"
        })
        assert response.status_code == 422
    
    def test_global_exception_handler(self, mock_auth):
        """Test global exception handling"""
        # This would require mocking an internal error
        # For now, we test that the endpoint exists and handles errors gracefully
        response = client.get("/health")
        assert response.status_code == 200

class TestWorkflowValidation:
    """Test workflow validation logic"""
    
    def test_workflow_name_validation(self):
        """Test workflow name validation"""
        # Valid names
        valid_names = [
            "valid-workflow",
            "workflow_123",
            "MyWorkflow",
            "a" * 100  # Maximum length
        ]
        
        for name in valid_names:
            request = WorkflowRequest(
                name=name,
                description="Test workflow"
            )
            assert request.name == name.strip()
        
        # Invalid names
        invalid_names = [
            "",  # Empty
            "   ",  # Whitespace only
            "a" * 101,  # Too long
        ]
        
        for name in invalid_names:
            with pytest.raises(ValueError):
                WorkflowRequest(
                    name=name,
                    description="Test workflow"
                )

class TestPerformance:
    """Test performance characteristics"""
    
    def test_concurrent_workflow_creation(self, workflow_engine):
        """Test creating multiple workflows concurrently"""
        async def create_workflow(i):
            request = WorkflowRequest(
                name=f"concurrent-workflow-{i}",
                description=f"Concurrent workflow {i}",
                priority=WorkflowPriority.MEDIUM
            )
            return await workflow_engine.create_workflow(request)
        
        # Create 10 workflows concurrently
        loop = asyncio.get_event_loop()
        workflow_ids = loop.run_until_complete(
            asyncio.gather(*[create_workflow(i) for i in range(10)])
        )
        
        assert len(workflow_ids) == 10
        assert len(set(workflow_ids)) == 10  # All unique
        
        # Verify all were created
        for workflow_id in workflow_ids:
            workflow = workflow_engine.get_workflow(workflow_id)
            assert workflow is not None
            assert workflow["status"] == WorkflowStatus.PENDING

class TestCompliance:
    """Test compliance monitoring"""
    
    def test_compliance_score_calculation(self, workflow_engine):
        """Test compliance score calculation"""
        # Create workflows with different compliance scores
        for i in range(5):
            request = WorkflowRequest(
                name=f"compliance-workflow-{i}",
                description=f"Compliance test workflow {i}",
                priority=WorkflowPriority.MEDIUM
            )
            workflow_id = asyncio.run(workflow_engine.create_workflow(request))
            
            # Manually set compliance score
            workflow = workflow_engine.get_workflow(workflow_id)
            workflow["compliance_score"] = 80.0 + (i * 5)  # 80, 85, 90, 95, 100
        
        # Calculate average compliance
        active_workflows = workflow_engine.active_workflows.values()
        total_score = sum(w.get("compliance_score", 100.0) for w in active_workflows)
        avg_score = total_score / len(active_workflows)
        
        assert avg_score == 90.0  # (80+85+90+95+100)/5

if __name__ == "__main__":
    # Run tests with coverage
    pytest.main([__file__, "--cov=main", "--cov-report=term-missing", "-v"])
